## Project Description

This project implements an Apache Airflow DAG to automate the extraction and analysis of Wikipedia pageview data. Specifically, it tracks hourly pageview trends for some big tech companies: Apple, Amazon, Facebook, Google, Microsoft, Tesla, IBM, Oracle.

---
## Tech Stack

â€¢ Orchestrator: Apache Airflow (DAGs)

â€¢ Database: PostgreSQL

â€¢ Language: Python 3.11
 
---
 ## Project Workflow
 
1.	Extract: Download and unzip Wikipedia pageview data for a specific hour in December 2025.

2.	Transform: Filter the dataset to isolate the targeted companies and extract pageview counts.

3.	Load: Insert the processed data into a PostgreSQL database.

4.	Analyze: Execute a SQL query to identify the company with the highest engagement.
--
### ğŸ“ Repository Structure
<pre>
Wikipedia-Pageview-Data-Pipeline/
â”‚
â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ wikipedia_company_views_etl_pipeline.py   # main DAG definition
â”‚   â”‚   â”œâ”€â”€ extract_views.py                          # extraction logic
â”‚   â”‚   â”œâ”€â”€ transform_views.py                        # transformation logic
â”‚   â”‚   â”œâ”€â”€ load_views.py                             # loading logic
â”‚   â”‚   â””â”€â”€                           
â”œâ”€â”€ pyenv/
â”œâ”€â”€ logs
â”œâ”€â”€ docker-compose.yaml                                    
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
</pre>
